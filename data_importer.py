import os
import io
import time
import shutil
import rarfile
import pandas as pd
from sqlalchemy import create_engine
from urllib.parse import quote_plus

# ================= é…ç½®åŒºåŸŸ =================
DB_CONFIG = {
    "user": "user",
    "password": "password",
    "host": "localhost",
    "port": "5433",
    "dbname": "quant_db"
}

# âœ… 1. è®¾ç½®æ ¹ç›®å½• (è„šæœ¬ä¼šå»è¿™ä¸ªç›®å½•ä¸‹æ‰¾å­æ–‡ä»¶å¤¹)
DATA_ROOT = r'D:\å•†å“æ•°æ®'

# âœ… 2. æŒ‡å®šè¦è¿›å…¥çš„å­æ–‡ä»¶å¤¹åç§°
# è„šæœ¬ä¼šä¾æ¬¡è¿›å…¥ D:\å•†å“æ•°æ®\2011, D:\å•†å“æ•°æ®\2012 ç­‰æ–‡ä»¶å¤¹
TARGET_FOLDERS = ['2011', '2012', '2013', '2014', '2015', '2016']

TEMP_FOLDER = './temp_extracted_data'
TARGET_TABLE = 'futures_tick_data'
COLUMN_MAPPING = [
    'å¸‚åœºä»£ç ', 'åˆçº¦ä»£ç ', 'æ—¶é—´', 'æœ€æ–°', 'æŒä»“', 'å¢ä»“', 
    'æˆäº¤é¢', 'æˆäº¤é‡', 'å¼€ä»“', 'å¹³ä»“', 'æˆäº¤ç±»å‹', 'æ–¹å‘', 
    'ä¹°ä¸€ä»·', 'å–ä¸€ä»·', 'ä¹°ä¸€é‡', 'å–ä¸€é‡'
]
# ===========================================

def get_engine():
    uri = f"postgresql+psycopg2://{DB_CONFIG['user']}:{quote_plus(DB_CONFIG['password'])}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}"
    return create_engine(uri)

def fast_copy_to_db(df, engine):
    if df.empty: return True
    conn = engine.raw_connection()
    cursor = conn.cursor()
    if len(df.columns) == len(COLUMN_MAPPING): df.columns = COLUMN_MAPPING
    df = df.where(pd.notnull(df), None)
    output = io.StringIO()
    df.to_csv(output, sep='\t', header=False, index=False)
    output.seek(0)
    try:
        cursor.copy_from(output, TARGET_TABLE, null='', sep='\t')
        conn.commit()
        return True
    except Exception as e:
        conn.rollback()
        print(f"X({e})", end="", flush=True)
        return False
    finally:
        cursor.close()
        conn.close()

def main():
    engine = get_engine()
    
    if os.path.exists(TEMP_FOLDER): shutil.rmtree(TEMP_FOLDER)
    os.makedirs(TEMP_FOLDER)

    BATCH_SIZE = 100 
    
    print(f"ğŸ¯ å‡†å¤‡å¤„ç†ä»¥ä¸‹å­æ–‡ä»¶å¤¹: {TARGET_FOLDERS}")

    # --- å¤–å±‚å¾ªç¯ï¼šéå†å¹´ä»½æ–‡ä»¶å¤¹ ---
    for year_folder in TARGET_FOLDERS:
        # æ‹¼å‡‘å®Œæ•´è·¯å¾„ï¼Œä¾‹å¦‚ D:\å•†å“æ•°æ®\2011
        current_path = os.path.join(DATA_ROOT, year_folder)
        
        print(f"\n{'='*50}")
        print(f"ğŸ“‚ è¿›å…¥æ–‡ä»¶å¤¹: {current_path}")

        # 1. æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(current_path):
            print(f"âš ï¸  [è·³è¿‡] æ‰¾ä¸åˆ°æ–‡ä»¶å¤¹: {current_path}")
            print(f"   (è¯·ç¡®è®¤ D:\\å•†å“æ•°æ® ä¸‹æ˜¯å¦æœ‰ {year_folder} è¿™ä¸ªæ–‡ä»¶å¤¹)")
            continue

        # 2. æ‰¾è¯¥æ–‡ä»¶å¤¹é‡Œçš„ RAR
        rar_files = [f for f in os.listdir(current_path) if f.lower().endswith('.rar')]
        rar_files.sort()
        
        if not rar_files:
            print(f"âš ï¸  [è·³è¿‡] æ–‡ä»¶å¤¹ {year_folder} é‡Œæ²¡æœ‰æ‰¾åˆ° .rar æ–‡ä»¶ã€‚")
            continue

        print(f"âœ… å‘ç° {len(rar_files)} ä¸ªå‹ç¼©åŒ…ï¼Œå¼€å§‹å¤„ç†...")

        # --- å†…å±‚å¾ªç¯ï¼šå¤„ç†æ¯ä¸ª RAR ---
        for idx, rar_file in enumerate(rar_files):
            rar_path = os.path.join(current_path, rar_file)
            print(f"[{idx+1}/{len(rar_files)}] {year_folder}/{rar_file} ...", end="", flush=True)
            
            try:
                with rarfile.RarFile(rar_path) as rf:
                    rf.extractall(TEMP_FOLDER)
                    csv_files = [f for f in rf.namelist() if f.lower().endswith('.csv')]
                    
                    print(f" è§£å‹ {len(csv_files)} CSV | å…¥åº“", end="", flush=True)
                    
                    dfs_buffer = [] 
                    for i, csv_f in enumerate(csv_files):
                        full_path = os.path.join(TEMP_FOLDER, csv_f)
                        try:
                            try: df = pd.read_csv(full_path, encoding='gbk')
                            except: df = pd.read_csv(full_path, encoding='utf-8')
                            
                            dfs_buffer.append(df)
                            
                            if len(dfs_buffer) >= BATCH_SIZE or i == len(csv_files) - 1:
                                if dfs_buffer:
                                    big_df = pd.concat(dfs_buffer, ignore_index=True)
                                    if fast_copy_to_db(big_df, engine):
                                        print(".", end="", flush=True)
                                    else:
                                        print("X", end="", flush=True)
                                    dfs_buffer = []
                        except: pass
                        finally:
                            if os.path.exists(full_path): os.remove(full_path)
                
                print(" å®Œæˆ", flush=True)
                
            except Exception as e:
                print(f"\n[é”™è¯¯] {e}", flush=True)
        # --- End of RAR loop ---

    print(f"\n{'='*50}")
    print(f"ğŸ‰ğŸ‰ğŸ‰ æ‰€æœ‰æŒ‡å®šçš„å¹´ä»½æ–‡ä»¶å¤¹å…¨éƒ¨å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()